{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Nl-24SebC5S"
      },
      "source": [
        "## Populate the hospital prescribing DB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO86zrHMbLiY"
      },
      "source": [
        "This (hacky) notebook is currently designed to be run from Google colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ6UDykvaaCx"
      },
      "source": [
        "We need to edit the code below to specify the details of the Postgres DB where we will put the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5yLeOvSZfh3"
      },
      "outputs": [],
      "source": [
        "import psycopg2\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Establish a connection to the PostgreSQL database\n",
        "\n",
        "def get_connection():\n",
        "  conn = psycopg2.connect(\n",
        "    dbname=\"hospitalprescribing2\",\n",
        "    user=\"hospitals\",\n",
        "    password=\"\",\n",
        "    host=\"\",\n",
        "    port=\"\"\n",
        "  )\n",
        "  return conn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqgObiLjapYm"
      },
      "source": [
        "Also, we need to get the dmd - unfortunately you need a (free) TRUD account for this:\n",
        "https://isd.digital.nhs.uk/trud/\n",
        "\n",
        "Modify the code below to use your download link for DMD from TRUD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWnr0vgJafrg"
      },
      "outputs": [],
      "source": [
        "!wget https://isd.digital.nhs.uk/download/api/v1/keys/[YOUR KEY HERE]/content/items/24/nhsbsa_dmd_11.2.0_20231120000001.zip -O dmd.zip\n",
        "!unzip dmd.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oxRkpslGZd7",
        "outputId": "e02cfe1f-ee1a-4aaf-905f-5539399b54e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded: downloaded_csvs/scmd_final_201904.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_201905.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_201906.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_201907.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_201908.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_201909.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_201910.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_201911.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_201912.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202001.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202002.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202003.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202004.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202005.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202006.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202007.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202008.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202009.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202010.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202011.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202012.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202101.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202102.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202103.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202104.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202105.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202106.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202107.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202108.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202109.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202110.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202111.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202112.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202201.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202202.csv\n",
            "Downloaded: downloaded_csvs/scmd_final_202203.csv\n",
            "Downloaded: downloaded_csvs/scmd_wip_202204.csv\n",
            "Downloaded: downloaded_csvs/scmd_wip_202205.csv\n",
            "Downloaded: downloaded_csvs/scmd_wip_202206.csv\n",
            "Downloaded: downloaded_csvs/scmd_wip_202207.csv\n",
            "Downloaded: downloaded_csvs/scmd_wip_202208.csv\n",
            "Downloaded: downloaded_csvs/scmd_wip_202209.csv\n",
            "Downloaded: downloaded_csvs/scmd_wip_202210.csv\n",
            "Downloaded: downloaded_csvs/scmd_wip_202211.csv\n",
            "Downloaded: downloaded_csvs/scmd_wip_202212.csv\n",
            "Downloaded: downloaded_csvs/scmd_provisional_202301.csv\n",
            "Downloaded: downloaded_csvs/scmd_provisional_202302.csv\n",
            "Downloaded: downloaded_csvs/scmd_provisional_202303.csv\n",
            "Downloaded: downloaded_csvs/scmd_provisional_202304.csv\n",
            "Downloaded: downloaded_csvs/scmd_provisional_202305.csv\n",
            "Downloaded: downloaded_csvs/scmd_provisional_202306.csv\n",
            "Downloaded: downloaded_csvs/scmd_provisional_202307.csv\n",
            "Downloaded: downloaded_csvs/scmd_provisional_202308.csv\n",
            "Downloaded: downloaded_csvs/scmd_provisional_202309.csv\n",
            "All files downloaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Step 1: Download the JSON from the provided URL\n",
        "url = \"https://opendata.nhsbsa.net/api/3/action/package_show?id=secondary-care-medicines-data-indicative-price\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Ensure the request was successful\n",
        "if response.status_code != 200:\n",
        "    raise Exception(\"Failed to download the JSON.\")\n",
        "\n",
        "data = response.json()\n",
        "\n",
        "# Step 2: Extract all the CSV file URLs from the JSON\n",
        "csv_urls = [resource['url'] for resource in data['result']['resources'] if resource['format'] == 'CSV']\n",
        "\n",
        "# Directory to save downloaded CSV files\n",
        "save_dir = \"downloaded_csvs\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Step 3: Download each CSV file\n",
        "for csv_url in csv_urls:\n",
        "    response = requests.get(csv_url)\n",
        "    filename = os.path.join(save_dir, csv_url.split(\"/\")[-1])\n",
        "\n",
        "    with open(filename, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "\n",
        "    print(f\"Downloaded: {filename}\")\n",
        "\n",
        "print(\"All files downloaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGMvphinG8L7",
        "outputId": "ba420a5a-90f7-48d2-f405-ece1bbfed3ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "scmd_final_202002.csv\n",
            "scmd_final_201904.csv\n",
            "scmd_final_202006.csv\n",
            "scmd_final_202110.csv\n",
            "scmd_final_202008.csv\n",
            "scmd_provisional_202307.csv\n",
            "scmd_final_201908.csv\n",
            "scmd_final_202105.csv\n",
            "scmd_wip_202211.csv\n",
            "scmd_provisional_202304.csv\n",
            "scmd_wip_202206.csv\n",
            "scmd_final_201909.csv\n",
            "scmd_wip_202205.csv\n",
            "scmd_final_202011.csv\n",
            "scmd_final_201906.csv\n",
            "scmd_provisional_202303.csv\n",
            "scmd_final_202111.csv\n",
            "scmd_final_202109.csv\n",
            "scmd_final_202202.csv\n",
            "scmd_final_202001.csv\n",
            "scmd_wip_202212.csv\n",
            "scmd_wip_202208.csv\n",
            "scmd_wip_202210.csv\n",
            "scmd_final_201911.csv\n",
            "scmd_provisional_202302.csv\n",
            "scmd_final_202101.csv\n",
            "scmd_final_202203.csv\n",
            "scmd_final_202112.csv\n",
            "scmd_final_202102.csv\n",
            "scmd_final_202108.csv\n",
            "scmd_provisional_202308.csv\n",
            "scmd_final_201912.csv\n",
            "scmd_wip_202209.csv\n",
            "scmd_provisional_202309.csv\n",
            "scmd_final_202010.csv\n",
            "scmd_provisional_202305.csv\n",
            "scmd_provisional_202301.csv\n",
            "scmd_final_202012.csv\n",
            "scmd_final_202201.csv\n",
            "scmd_final_202005.csv\n",
            "scmd_provisional_202306.csv\n",
            "scmd_wip_202204.csv\n",
            "scmd_final_201910.csv\n",
            "scmd_wip_202207.csv\n",
            "scmd_final_201905.csv\n",
            "scmd_final_201907.csv\n",
            "scmd_final_202107.csv\n",
            "scmd_final_202104.csv\n",
            "scmd_final_202003.csv\n",
            "scmd_final_202103.csv\n",
            "scmd_final_202004.csv\n",
            "scmd_final_202106.csv\n",
            "scmd_final_202007.csv\n",
            "scmd_final_202009.csv\n",
            "Data has been successfully imported into the PostgreSQL table!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "conn = get_connection()\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Create the temporary table\n",
        "create_temp_table_query = \"\"\"\n",
        "CREATE TEMP TABLE temp_secondary_care_medicines_data (\n",
        "    YEAR_MONTH INT,\n",
        "    ODS_CODE TEXT,\n",
        "    VMP_SNOMED_CODE BIGINT,\n",
        "    VMP_PRODUCT_NAME TEXT,\n",
        "    UNIT_OF_MEASURE_IDENTIFIER BIGINT,\n",
        "    UNIT_OF_MEASURE_NAME TEXT,\n",
        "    TOTAL_QUANITY_IN_VMP_UNIT FLOAT,\n",
        "    INDICATIVE_COST FLOAT\n",
        ")\n",
        "\"\"\"\n",
        "cursor.execute(create_temp_table_query)\n",
        "\n",
        "# Create the mapping tables\n",
        "create_vmp_mapping_table_query = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS vmp_code_name_mapping (\n",
        "    VMP_SNOMED_CODE BIGINT,\n",
        "    VMP_PRODUCT_NAME TEXT,\n",
        "    PRIMARY KEY (VMP_SNOMED_CODE, VMP_PRODUCT_NAME)\n",
        ")\n",
        "\"\"\"\n",
        "cursor.execute(create_vmp_mapping_table_query)\n",
        "\n",
        "create_unit_mapping_table_query = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS unit_code_name_mapping (\n",
        "    UNIT_OF_MEASURE_IDENTIFIER BIGINT,\n",
        "    UNIT_OF_MEASURE_NAME TEXT,\n",
        "    PRIMARY KEY (UNIT_OF_MEASURE_IDENTIFIER, UNIT_OF_MEASURE_NAME)\n",
        ")\n",
        "\"\"\"\n",
        "cursor.execute(create_unit_mapping_table_query)\n",
        "\n",
        "# Modify the main table\n",
        "create_main_table_query = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS secondary_care_medicines_data (\n",
        "    YEAR_MONTH INT,\n",
        "    ODS_CODE TEXT,\n",
        "    VMP_SNOMED_CODE BIGINT,\n",
        "    UNIT_OF_MEASURE_IDENTIFIER BIGINT,\n",
        "    TOTAL_QUANITY_IN_VMP_UNIT FLOAT,\n",
        "    INDICATIVE_COST FLOAT\n",
        ")\n",
        "\"\"\"\n",
        "cursor.execute(create_main_table_query)\n",
        "\n",
        "csv_dir = \"downloaded_csvs\"\n",
        "tsv_dir = \"converted_tsvs\"\n",
        "if not os.path.exists(tsv_dir):\n",
        "    os.makedirs(tsv_dir)\n",
        "\n",
        "for filename in os.listdir(csv_dir):\n",
        "    print(filename)\n",
        "    if filename.endswith(\".csv\"):\n",
        "        csv_filepath = os.path.join(csv_dir, filename)\n",
        "        tsv_filepath = os.path.join(tsv_dir, filename.replace('.csv', '.tsv'))\n",
        "\n",
        "        # Convert CSV to TSV with pandas\n",
        "        df = pd.read_csv(csv_filepath)\n",
        "        df.to_csv(tsv_filepath, sep='\\t', index=False)\n",
        "\n",
        "        with open(tsv_filepath, 'r') as file:\n",
        "            next(file)  # Skip header row\n",
        "            cursor.copy_from(file, 'temp_secondary_care_medicines_data', sep='\\t', null=\"\")\n",
        "\n",
        "        # Transfer data to the mapping tables (ignoring duplicates)\n",
        "        cursor.execute(\"\"\"\n",
        "        INSERT INTO vmp_code_name_mapping (VMP_SNOMED_CODE, VMP_PRODUCT_NAME)\n",
        "        SELECT DISTINCT VMP_SNOMED_CODE, VMP_PRODUCT_NAME FROM temp_secondary_care_medicines_data\n",
        "         ON CONFLICT (VMP_SNOMED_CODE, VMP_PRODUCT_NAME) DO NOTHING;\n",
        "\n",
        "        \"\"\")\n",
        "\n",
        "        cursor.execute(\"\"\"\n",
        "        INSERT INTO unit_code_name_mapping (UNIT_OF_MEASURE_IDENTIFIER, UNIT_OF_MEASURE_NAME)\n",
        "        SELECT DISTINCT UNIT_OF_MEASURE_IDENTIFIER, UNIT_OF_MEASURE_NAME FROM temp_secondary_care_medicines_data\n",
        "\n",
        "        ON CONFLICT (UNIT_OF_MEASURE_IDENTIFIER, UNIT_OF_MEASURE_NAME) DO NOTHING;\n",
        "\n",
        "        \"\"\")\n",
        "\n",
        "        # Transfer data to the main table\n",
        "        cursor.execute(\"\"\"\n",
        "        INSERT INTO secondary_care_medicines_data (YEAR_MONTH, ODS_CODE, VMP_SNOMED_CODE, UNIT_OF_MEASURE_IDENTIFIER, TOTAL_QUANITY_IN_VMP_UNIT, INDICATIVE_COST)\n",
        "        SELECT YEAR_MONTH, ODS_CODE, VMP_SNOMED_CODE, UNIT_OF_MEASURE_IDENTIFIER, TOTAL_QUANITY_IN_VMP_UNIT, INDICATIVE_COST\n",
        "        FROM temp_secondary_care_medicines_data;\n",
        "        \"\"\")\n",
        "\n",
        "        # Clear the temporary table for the next iteration\n",
        "        cursor.execute(\"TRUNCATE temp_secondary_care_medicines_data;\")\n",
        "\n",
        "conn.commit()\n",
        "cursor.close()\n",
        "conn.close()\n",
        "\n",
        "\"\"\"\n",
        "Now we also need\n",
        "CREATE INDEX secondary_care_medicines_data_year_month_idx ON public.secondary_care_medicines_data (year_month);\n",
        "CREATE INDEX secondary_care_medicines_data_vmp_snomed_code_idx ON public.secondary_care_medicines_data (vmp_snomed_code);\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "print(\"Data has been successfully imported into the PostgreSQL table!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R3JkDEoI-la",
        "outputId": "619ce4f3-fd54-4a98-beb8-0dc2eb05c4d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-11-25 16:31:49--  https://files.digital.nhs.uk/assets/ods/current/etr.zip\n",
            "Resolving files.digital.nhs.uk (files.digital.nhs.uk)... 52.84.52.98, 52.84.52.19, 52.84.52.76, ...\n",
            "Connecting to files.digital.nhs.uk (files.digital.nhs.uk)|52.84.52.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 206157 (201K) [application/zip]\n",
            "Saving to: ‘etr.zip’\n",
            "\n",
            "etr.zip             100%[===================>] 201.33K   793KB/s    in 0.3s    \n",
            "\n",
            "2023-11-25 16:31:52 (793 KB/s) - ‘etr.zip’ saved [206157/206157]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://files.digital.nhs.uk/assets/ods/current/etr.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4uOVsYjUq84",
        "outputId": "dd8381af-a615-461c-a573-f8d776779a39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  etr.zip\n",
            "  inflating: etr.csv                 \n",
            "  inflating: etr.pdf                 \n"
          ]
        }
      ],
      "source": [
        "!unzip etr.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXMo-rqzUtOn",
        "outputId": "8415ce45-5bc0-4150-9df7-54cc17b1897b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data has been successfully imported into the PostgreSQL table!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import psycopg2\n",
        "import os\n",
        "\n",
        "# Step 1: Convert \"file.csv\" to \"file.tsv\"\n",
        "csv_filepath = \"etr.csv\"\n",
        "tsv_filepath = csv_filepath.replace('.csv', '.tsv')\n",
        "\n",
        "df = pd.read_csv(csv_filepath,  header=None)\n",
        "\n",
        "df = df.iloc[:, :2]\n",
        "df.to_csv(tsv_filepath, sep='\\t', index=False)\n",
        "\n",
        "\n",
        "# Step 2: Connect to the PostgreSQL database\n",
        "conn = get_connection()\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Step 3: Create a new table for the data\n",
        "create_table_query = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS ods_data (\n",
        "    Code TEXT,\n",
        "    Name TEXT\n",
        ")\n",
        "\"\"\"\n",
        "cursor.execute(create_table_query)\n",
        "\n",
        "# Step 4: Upload data from the TSV file into the new table\n",
        "with open(tsv_filepath, 'r') as file:\n",
        "    next(file)  # Skip header row\n",
        "    cursor.copy_from(file, 'ods_data', sep='\\t', null=\"\")\n",
        "\n",
        "conn.commit()\n",
        "cursor.close()\n",
        "conn.close()\n",
        "\n",
        "print(\"Data has been successfully imported into the PostgreSQL table!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3bRbvldAVaQf"
      },
      "outputs": [],
      "source": [
        "import psycopg2\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Assuming the XML data file is named \"ingredient_data.xml\"\n",
        "xml_filepath = \"f_ingredient2_3140923.xml\"\n",
        "tsv_filepath = \"ingredient_data.tsv\"\n",
        "\n",
        "# Step 1: Read and parse the XML data file\n",
        "tree = ET.parse(xml_filepath)\n",
        "root = tree.getroot()\n",
        "\n",
        "# Step 2: Extract relevant data fields from the XML file and write to TSV\n",
        "with open(tsv_filepath, 'w') as tsv_file:\n",
        "    for ing in root.findall('ING'):\n",
        "        isid = ing.find('ISID').text\n",
        "        isiddt = ing.find('ISIDDT').text if ing.find('ISIDDT') is not None else '\\\\N'  # Using PostgreSQL's default representation for NULL\n",
        "        isidprev = ing.find('ISIDPREV').text if ing.find('ISIDPREV') is not None else '\\\\N'\n",
        "        invalid = ing.find('INVALID').text if ing.find('INVALID') is not None else '\\\\N'\n",
        "        nm = ing.find('NM').text\n",
        "        tsv_file.write(f\"{isid}\\t{isiddt}\\t{isidprev}\\t{invalid}\\t{nm}\\n\")\n",
        "\n",
        "# Step 3: Connect to the PostgreSQL database\n",
        "conn = get_connection()\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Step 4: Create a new table for the data (if not exists)\n",
        "create_table_query = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS ingredient_data (\n",
        "    ISID BIGINT,\n",
        "    ISIDDT DATE,\n",
        "    ISIDPREV BIGINT,\n",
        "    INVALID INTEGER,\n",
        "    NM TEXT\n",
        ")\n",
        "\"\"\"\n",
        "cursor.execute(create_table_query)\n",
        "\n",
        "# Step 5: Upload data from the TSV file into the new table\n",
        "with open(tsv_filepath, 'r') as tsv_file:\n",
        "    cursor.copy_from(tsv_file, 'ingredient_data', sep='\\t', null=\"\\\\N\")  # Using PostgreSQL's default representation for NULL\n",
        "\n",
        "conn.commit()\n",
        "cursor.close()\n",
        "conn.close()\n",
        "\n",
        "print(\"Ingredient data has been successfully imported into the PostgreSQL table!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j27sZV5ZdKG0",
        "outputId": "e7418ad1-5551-4aaf-e35f-d1fa70268415"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ingredient data has been successfully imported into the PostgreSQL table!\n"
          ]
        }
      ],
      "source": [
        "import psycopg2\n",
        "import xml.etree.ElementTree as ET\n",
        "import glob\n",
        "# Assuming the XML data file is named \"ingredient_data.xml\"\n",
        "\n",
        "xml_filepath = \"f_ingredient2_*.xml\"\n",
        "xml_filepath = glob.glob(xml_filepath)[0]\n",
        "\n",
        "\n",
        "tsv_filepath = \"ingredient_data.tsv\"\n",
        "\n",
        "# Step 1: Read and parse the XML data file\n",
        "tree = ET.parse(xml_filepath)\n",
        "root = tree.getroot()\n",
        "\n",
        "# Step 2: Extract relevant data fields from the XML file and write to TSV\n",
        "with open(tsv_filepath, 'w') as tsv_file:\n",
        "    for ing in root.findall('ING'):\n",
        "        isid = ing.find('ISID').text\n",
        "        isiddt = ing.find('ISIDDT').text if ing.find('ISIDDT') is not None else '\\\\N'  # Using PostgreSQL's default representation for NULL\n",
        "        isidprev = ing.find('ISIDPREV').text if ing.find('ISIDPREV') is not None else '\\\\N'\n",
        "        invalid = ing.find('INVALID').text if ing.find('INVALID') is not None else '\\\\N'\n",
        "        nm = ing.find('NM').text\n",
        "        tsv_file.write(f\"{isid}\\t{isiddt}\\t{isidprev}\\t{invalid}\\t{nm}\\n\")\n",
        "\n",
        "# Step 3: Connect to the PostgreSQL database\n",
        "conn = get_connection()\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Step 4: Create a new table for the data (if not exists)\n",
        "create_table_query = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS ingredient_data (\n",
        "    ISID BIGINT,\n",
        "    ISIDDT DATE,\n",
        "    ISIDPREV BIGINT,\n",
        "    INVALID INTEGER,\n",
        "    NM TEXT\n",
        ")\n",
        "\"\"\"\n",
        "cursor.execute(create_table_query)\n",
        "\n",
        "# Step 5: Upload data from the TSV file into the new table\n",
        "with open(tsv_filepath, 'r') as tsv_file:\n",
        "    cursor.copy_from(tsv_file, 'ingredient_data', sep='\\t', null=\"\\\\N\")  # Using PostgreSQL's default representation for NULL\n",
        "\n",
        "conn.commit()\n",
        "cursor.close()\n",
        "conn.close()\n",
        "\n",
        "print(\"Ingredient data has been successfully imported into the PostgreSQL table!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYWXIWi2eeFZ",
        "outputId": "8bb7e4cd-1b1c-4548-d00f-fe5c141626c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VTM data has been successfully imported into the PostgreSQL table!\n"
          ]
        }
      ],
      "source": [
        "import psycopg2\n",
        "import xml.etree.ElementTree as ET\n",
        "import glob\n",
        "# Assuming the XML data file is named \"ingredient_data.xml\"\n",
        "\n",
        "xml_filepath = \"f_vtm2_*.xml\"\n",
        "xml_filepath = glob.glob(xml_filepath)[0]\n",
        "tsv_filepath = \"vtm_data.tsv\"\n",
        "\n",
        "# Step 1: Read and parse the XML data file\n",
        "tree = ET.parse(xml_filepath)\n",
        "root = tree.getroot()\n",
        "\n",
        "# Step 2: Extract relevant data fields from the XML file and write to TSV\n",
        "with open(tsv_filepath, 'w') as tsv_file:\n",
        "    for vtm in root.findall('VTM'):\n",
        "        vtmid = vtm.find('VTMID').text\n",
        "        invalid = vtm.find('INVALID').text if vtm.find('INVALID') is not None else '\\\\N'  # Using PostgreSQL's default representation for NULL\n",
        "        nm = vtm.find('NM').text\n",
        "        abbrevnm = vtm.find('ABBREVNM').text if vtm.find('ABBREVNM') is not None else '\\\\N'\n",
        "        vtmidprev = vtm.find('VTMIDPREV').text if vtm.find('VTMIDPREV') is not None else '\\\\N'\n",
        "        vtmiddt = vtm.find('VTMIDDT').text if vtm.find('VTMIDDT') is not None else '\\\\N'\n",
        "        tsv_file.write(f\"{vtmid}\\t{invalid}\\t{nm}\\t{abbrevnm}\\t{vtmidprev}\\t{vtmiddt}\\n\")\n",
        "\n",
        "# Step 3: Connect to the PostgreSQL database\n",
        "conn = get_connection()\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Step 4: Create a new table for the data (if not exists)\n",
        "create_table_query = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS vtm_data (\n",
        "    VTMID BIGINT,\n",
        "    INVALID INTEGER,\n",
        "    NM TEXT,\n",
        "    ABBREVNM TEXT,\n",
        "    VTMIDPREV BIGINT,\n",
        "    VTMIDDT DATE\n",
        ")\n",
        "\"\"\"\n",
        "cursor.execute(create_table_query)\n",
        "\n",
        "# Step 5: Upload data from the TSV file into the new table\n",
        "with open(tsv_filepath, 'r') as tsv_file:\n",
        "    cursor.copy_from(tsv_file, 'vtm_data', sep='\\t', null=\"\\\\N\")  # Using PostgreSQL's default representation for NULL\n",
        "\n",
        "conn.commit()\n",
        "cursor.close()\n",
        "conn.close()\n",
        "\n",
        "print(\"VTM data has been successfully imported into the PostgreSQL table!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQMHhnqyepyh",
        "outputId": "b4e2275d-e0fb-4bef-e5fc-18f65d8adb29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "VMP to VTM links with dose information have been successfully imported into the PostgreSQL table!\n"
          ]
        }
      ],
      "source": [
        "import psycopg2\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "xml_filepath = \"f_vmp2_*.xml\"\n",
        "xml_filepath = glob.glob(xml_filepath)[0]\n",
        "tsv_filepath = \"vmp_vtm_links.tsv\"\n",
        "\n",
        "# Step 1: Read and parse the XML data file\n",
        "tree = ET.parse(xml_filepath)\n",
        "root = tree.getroot()\n",
        "\n",
        "# Step 2: Extract relevant data fields from the XML file and write to TSV\n",
        "with open(tsv_filepath, 'w') as tsv_file:\n",
        "    for vmp in root.find('VMPS').findall('VMP'):\n",
        "        vpid = vmp.find('VPID').text\n",
        "        vpid_prev = vmp.find('VPIDPREV').text if vmp.find('VPIDPREV') is not None else '\\\\N'\n",
        "        vtmid = vmp.find('VTMID').text if vmp.find('VTMID') is not None else '\\\\N'  # Using PostgreSQL's default representation for NULL\n",
        "        udfs = vmp.find('UDFS').text if vmp.find('UDFS') is not None else '\\\\N'\n",
        "        udfs_uomcd = vmp.find('UDFS_UOMCD').text if vmp.find('UDFS_UOMCD') is not None else '\\\\N'\n",
        "        unit_dose_uomcd = vmp.find('UNIT_DOSE_UOMCD').text if vmp.find('UNIT_DOSE_UOMCD') is not None else '\\\\N'\n",
        "        tsv_file.write(f\"{vpid}\\t{vpid_prev}\\t{vtmid}\\t{udfs}\\t{udfs_uomcd}\\t{unit_dose_uomcd}\\n\")\n",
        "\n",
        "# Step 3: Connect to the PostgreSQL database\n",
        "conn = get_connection()\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Step 4: Create a new table for the data (if not exists)\n",
        "create_table_query = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS vmp_stuff (\n",
        "    VPID BIGINT,\n",
        "    VPID_PREV BIGINT,\n",
        "    VTMID BIGINT,\n",
        "    UDFS FLOAT,\n",
        "    UDFS_UOMCD BIGINT,\n",
        "    UNIT_DOSE_UOMCD BIGINT\n",
        ")\n",
        "\"\"\"\n",
        "cursor.execute(create_table_query)\n",
        "\n",
        "# Step 5: Upload data from the TSV file into the new table\n",
        "with open(tsv_filepath, 'r') as tsv_file:\n",
        "    cursor.copy_from(tsv_file, 'vmp_stuff', sep='\\t', null=\"\\\\N\")  # Using PostgreSQL's default representation for NULL\n",
        "\n",
        "conn.commit()\n",
        "cursor.close()\n",
        "conn.close()\n",
        "\n",
        "print(\"VMP to VTM links with dose information have been successfully imported into the PostgreSQL table!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqoOE9nwe5t7",
        "outputId": "cd010d5b-be26-40d8-966a-79f28955f7bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Virtual product ingredient data, including denominators, have been successfully imported into the PostgreSQL table!\n"
          ]
        }
      ],
      "source": [
        "import psycopg2\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Use the provided XML data file\n",
        "xml_filepath = \"f_vmp2_*.xml\"\n",
        "xml_filepath = glob.glob(xml_filepath)[0]\n",
        "tsv_filepath = \"virtual_product_ingredient.tsv\"\n",
        "\n",
        "# Step 1: Read and parse the XML data file\n",
        "tree = ET.parse(xml_filepath)\n",
        "root = tree.getroot()\n",
        "\n",
        "# Step 2: Extract relevant data fields from the XML file and write to TSV\n",
        "with open(tsv_filepath, 'w') as tsv_file:\n",
        "    for vpi in root.find('VIRTUAL_PRODUCT_INGREDIENT').findall('VPI'):\n",
        "        vpid = vpi.find('VPID').text\n",
        "        isid = vpi.find('ISID').text\n",
        "        basis_strntcd = vpi.find('BASIS_STRNTCD').text if vpi.find('BASIS_STRNTCD') is not None else '\\\\N'\n",
        "        strnt_nmrtr_val = vpi.find('STRNT_NMRTR_VAL').text if vpi.find('STRNT_NMRTR_VAL') is not None else '\\\\N'\n",
        "        strnt_nmrtr_uomcd = vpi.find('STRNT_NMRTR_UOMCD').text if vpi.find('STRNT_NMRTR_UOMCD') is not None else '\\\\N'\n",
        "        strnt_dnmtr_val = vpi.find('STRNT_DNMTR_VAL').text if vpi.find('STRNT_DNMTR_VAL') is not None else '\\\\N'\n",
        "        strnt_dnmtr_uomcd = vpi.find('STRNT_DNMTR_UOMCD').text if vpi.find('STRNT_DNMTR_UOMCD') is not None else '\\\\N'\n",
        "        tsv_file.write(f\"{vpid}\\t{isid}\\t{basis_strntcd}\\t{strnt_nmrtr_val}\\t{strnt_nmrtr_uomcd}\\t{strnt_dnmtr_val}\\t{strnt_dnmtr_uomcd}\\n\")\n",
        "\n",
        "# Step 3: Connect to the PostgreSQL database\n",
        "conn = get_connection()\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Step 4: Create a new table for the data (if not exists)\n",
        "create_table_query = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS virtual_product_ingredient (\n",
        "    VPID BIGINT,\n",
        "    ISID BIGINT,\n",
        "    BASIS_STRNTCD INTEGER,\n",
        "    STRNT_NMRTR_VAL FLOAT,\n",
        "    STRNT_NMRTR_UOMCD BIGINT,\n",
        "    STRNT_DNMTR_VAL FLOAT,\n",
        "    STRNT_DNMTR_UOMCD BIGINT\n",
        ")\n",
        "\"\"\"\n",
        "cursor.execute(create_table_query)\n",
        "\n",
        "# Step 5: Upload data from the TSV file into the new table\n",
        "with open(tsv_filepath, 'r') as tsv_file:\n",
        "    cursor.copy_from(tsv_file, 'virtual_product_ingredient', sep='\\t', null=\"\\\\N\")  # Using PostgreSQL's default representation for NULL\n",
        "\n",
        "conn.commit()\n",
        "cursor.close()\n",
        "conn.close()\n",
        "\n",
        "print(\"Virtual product ingredient data, including denominators, have been successfully imported into the PostgreSQL table!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHBqQq1FfUDJ"
      },
      "outputs": [],
      "source": [
        "import psycopg2\n",
        "\n",
        "sql = \"\"\"CREATE TABLE unit_data (\n",
        "\tuom_cd int8 NULL,\n",
        "\toriginal_unit_name varchar NULL,\n",
        "\tbasic_unit varchar NULL,\n",
        "\tnumber_of_basic_unit numeric NULL\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "sql2 = \"\"\"INSERT INTO public.unit_data (uom_cd,original_unit_name,basic_unit,number_of_basic_unit) VALUES\n",
        "\t (258718000,'mmol','mmol',1),\n",
        "\t (258773002,'ml','ml',1),\n",
        "\t (767525000,'unit','unit',1),\n",
        "\t (418931004,'GBq','GBq',1),\n",
        "\t (229034000,'Mbq','Mbq',1),\n",
        "\t (258719008,'umol','umol',1),\n",
        "\t (258997004,'IU','IU',1),\n",
        "\t (258731005,'ppm','ppm',1),\n",
        "\t (258774008,'ul','ml',0.001),\n",
        "\t (282113003,'nl','ml',0.000001);\n",
        "INSERT INTO public.unit_data (uom_cd,original_unit_name,basic_unit,number_of_basic_unit) VALUES\n",
        "\t (258684004,'mg','g',0.001),\n",
        "\t (258685003,'ug','g',0.000001),\n",
        "\t (258686002,'ng','g',0.000000001),\n",
        "\t (258682000,'g','g',1);\n",
        "\"\"\"\n",
        "conn = get_connection()\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute(sql)\n",
        "\n",
        "conn.commit()\n",
        "cursor.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykS4iXP9geRB"
      },
      "outputs": [],
      "source": [
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute(sql2)\n",
        "\n",
        "conn.commit()\n",
        "cursor.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzcPBm6kU6kH"
      },
      "outputs": [],
      "source": [
        "conn = get_connection()\n",
        "sql = \"\"\"\n",
        "CREATE INDEX ingredient_data_isid_idx ON public.ingredient_data USING btree (isid);\n",
        "\n",
        "CREATE INDEX vtm_data_vtmid_idx ON public.vtm_data USING btree (vtmid);\n",
        "\n",
        "CREATE INDEX virtual_product_ingredient_isid_idx ON public.virtual_product_ingredient USING btree (isid);\n",
        "\n",
        "CREATE INDEX virtual_product_ingredient_vpid_idx ON public.virtual_product_ingredient USING btree (vpid);\n",
        "\"\"\"\n",
        "\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute(sql)\n",
        "\n",
        "conn.commit()\n",
        "cursor.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0SQ5CW4Vd8x"
      },
      "outputs": [],
      "source": [
        "\n",
        "conn = get_connection()\n",
        "sql = \"\"\"\n",
        "CREATE INDEX secondary_care_medicines_data_vmp_snomed_code_idx ON public.secondary_care_medicines_data USING btree (vmp_snomed_code);\n",
        "\n",
        "CREATE INDEX secondary_care_medicines_data_year_month_idx ON public.secondary_care_medicines_data USING btree (year_month);\n",
        "\"\"\"\n",
        "\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute(sql)\n",
        "\n",
        "conn.commit()\n",
        "cursor.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conn = get_connection()\n",
        "\n",
        "# SQL commands to alter the table and update the new column\n",
        "sql = \"\"\"\n",
        "ALTER TABLE ingredient_data\n",
        "ADD COLUMN has_usage BOOLEAN DEFAULT FALSE;\n",
        "\n",
        "UPDATE ingredient_data\n",
        "SET has_usage = EXISTS (\n",
        "    SELECT 1\n",
        "    FROM secondary_care_medicines_data\n",
        "    INNER JOIN virtual_product_ingredient\n",
        "        ON virtual_product_ingredient.vpid = secondary_care_medicines_data.VMP_SNOMED_CODE\n",
        "    WHERE virtual_product_ingredient.isid = ingredient_data.isid\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Executing the SQL commands\n",
        "cursor.execute(sql)\n",
        "\n",
        "# Committing the changes to the database\n",
        "conn.commit()\n",
        "\n",
        "# Closing the cursor\n",
        "cursor.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "conn =get_connection()\n",
        "cursor = conn.cursor()\n",
        "xml_filepath = \"f_vmp2_*.xml\"\n",
        "xml_filepath = glob.glob(xml_filepath)[0]\n",
        "\n",
        "route_tsv_filepath = \"drug_route_data.tsv\"\n",
        "\n",
        "# Step 1: Read and parse the XML data file\n",
        "tree = ET.parse(xml_filepath)\n",
        "root = tree.getroot()\n",
        "\n",
        "\n",
        "# Step 2.1: Extract Drug Route data fields and write to another TSV\n",
        "with open(route_tsv_filepath, 'w') as tsv_file:\n",
        "    for droute in root.findall(\".//DROUTE\"):\n",
        "        vpid = droute.find('VPID').text if droute.find('VPID') is not None else '\\\\N'\n",
        "        route_cd = droute.find('ROUTECD').text if droute.find('ROUTECD') is not None else '\\\\N'\n",
        "        tsv_file.write(f\"{vpid}\\t{route_cd}\\n\")\n",
        "\n",
        "# Step 3: Connect to the PostgreSQL database\n",
        "conn = get_connection()\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Step 4: Create a new table for VMP data (if not exists)\n",
        "# ... existing code to create vmp_stuff table ...\n",
        "\n",
        "# Step 4.1: Create a new table for Drug Route data (if not exists)\n",
        "create_route_table_query = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS drug_route (\n",
        "    VPID BIGINT,\n",
        "    ROUTECD BIGINT\n",
        ")\n",
        "\"\"\"\n",
        "cursor.execute(create_route_table_query)\n",
        "\n",
        "# Step 5: Upload VMP data from the TSV file into the new table\n",
        "# ... existing code to upload VMP data ...\n",
        "\n",
        "# Step 5.1: Upload Drug Route data from the TSV file into the new table\n",
        "with open(route_tsv_filepath, 'r') as tsv_file:\n",
        "    cursor.copy_from(tsv_file, 'drug_route', sep='\\t', null=\"\\\\N\")  # Using PostgreSQL's default representation for NULL\n",
        "\n",
        "conn.commit()\n",
        "cursor.close()\n",
        "conn.close()\n",
        "\n",
        "print(\"Data has been successfully imported into the PostgreSQL table!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def update_and_clean_drug_route_table():\n",
        "    # SQL query to update the table\n",
        "    update_query = \"\"\"\n",
        "    UPDATE drug_route\n",
        "    SET ROUTECD = -1\n",
        "    WHERE VPID IN (\n",
        "        SELECT VPID\n",
        "        FROM drug_route\n",
        "        GROUP BY VPID\n",
        "        HAVING COUNT(ROUTECD) > 1\n",
        "    );\n",
        "    \"\"\"\n",
        "\n",
        "    # SQL query to delete duplicates\n",
        "    delete_duplicates_query = \"\"\"\n",
        "    DELETE FROM drug_route\n",
        "    WHERE ctid NOT IN (\n",
        "        SELECT MIN(ctid)\n",
        "        FROM drug_route\n",
        "        GROUP BY VPID\n",
        "    );\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Establish a database connection\n",
        "        conn = get_connection()\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Execute the update query\n",
        "        cursor.execute(update_query)\n",
        "\n",
        "        # Execute the delete duplicates query\n",
        "        cursor.execute(delete_duplicates_query)\n",
        "\n",
        "        # Commit the changes\n",
        "        conn.commit()\n",
        "\n",
        "        print(\"Table updated and duplicates removed successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "    finally:\n",
        "        # Close the cursor and connection\n",
        "        if cursor:\n",
        "            cursor.close()\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "# Call the function to update and clean the table\n",
        "update_and_clean_drug_route_table()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
